#!/usr/bin/python
# -*- coding:utf-8 -*-
"""
èŒä½æŠ€æœ¯æ ˆåˆ†ææ¨¡å—
ä» CSV æ–‡ä»¶è¯»å–èŒä½æè¿°ï¼Œåˆ†æå…±æ€§æŠ€æœ¯æ ˆï¼Œè¾“å‡ºå­¦ä¹ å»ºè®®
"""

import csv
import re
from collections import Counter
import json

# ==================== é…ç½®å‚æ•° ====================

# è¾“å…¥æ–‡ä»¶ï¼ˆçˆ¬è™«ç”Ÿæˆçš„æ•°æ®ï¼‰
INPUT_FILE = 'data.csv'

# è¾“å‡ºæ–‡ä»¶
OUTPUT_FILE = 'tech_stack_analysis.json'

# æŠ€æœ¯æ ˆå…³é”®è¯åº“
TECH_KEYWORDS = {
    'ç¼–ç¨‹è¯­è¨€': [
        'Python', 'Java', 'JavaScript', 'TypeScript', 'Go', 'Golang',
        'C++', 'C#', 'Rust', 'PHP', 'Ruby', 'Swift', 'Kotlin', 'Scala'
    ],
    'å‰ç«¯æ¡†æ¶': [
        'React', 'Vue', 'Angular', 'Next.js', 'Nuxt.js',
        'uni-app', 'Flutter', 'Electron', 'React Native'
    ],
    'åç«¯æ¡†æ¶': [
        'Django', 'Flask', 'FastAPI', 'Spring Boot', 'Spring Cloud',
        'Express', 'Koa', 'Egg.js', 'Gin', 'Beego', 'Laravel'
    ],
    'AI/MLæ¡†æ¶': [
        'PyTorch', 'TensorFlow', 'Keras', 'scikit-learn', 'Pandas',
        'NumPy', 'Transformers', 'LangChain', 'OpenAI API', 'LLM',
        'Agent', 'RAG', 'Fine-tuning', 'Prompt Engineering'
    ],
    'æ•°æ®åº“': [
        'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Elasticsearch',
        'ClickHouse', 'Doris', 'Hive', 'HBase', 'OceanBase'
    ],
    'ä¸­é—´ä»¶/å·¥å…·': [
        'Kafka', 'RabbitMQ', 'RocketMQ', 'Docker', 'Kubernetes',
        'K8s', 'Jenkins', 'Git', 'GitLab', 'Linux', 'Nginx'
    ],
    'äº‘å¹³å°': [
        'AWS', 'Azure', 'GCP', 'é˜¿é‡Œäº‘', 'è…¾è®¯äº‘', 'åä¸ºäº‘',
        'Serverless', 'Lambda', 'Function Compute'
    ]
}

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================

def load_job_descriptions(csv_file):
    """ä»CSVæ–‡ä»¶åŠ è½½èŒä½æè¿°"""
    descriptions = []

    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            desc = row.get('èŒä½æè¿°', '').strip()
            if desc and len(desc) > 10:
                descriptions.append({
                    'èŒä½': row.get('èŒä½', ''),
                    'å…¬å¸': row.get('å…¬å¸', ''),
                    'è–ªèµ„': row.get('è–ªèµ„', ''),
                    'æè¿°': desc
                })

    print(f"âœ“ åŠ è½½äº† {len(descriptions)} ä¸ªèŒä½æè¿°")
    return descriptions


def extract_tech_stack(descriptions):
    """ä»èŒä½æè¿°ä¸­æå–æŠ€æœ¯æ ˆå…³é”®è¯"""
    print("\nå¼€å§‹åˆ†ææŠ€æœ¯æ ˆ...")

    tech_stats = {category: Counter() for category in TECH_KEYWORDS}
    total_jobs = len(descriptions)

    for idx, job in enumerate(descriptions, 1):
        desc = job['æè¿°']

        # éå†æ‰€æœ‰æŠ€æœ¯ç±»åˆ«
        for category, keywords in TECH_KEYWORDS.items():
            for keyword in keywords:
                # ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
                pattern = re.compile(re.escape(keyword), re.IGNORECASE)
                if pattern.search(desc):
                    tech_stats[category][keyword] += 1

        if idx % 10 == 0:
            print(f"  å·²åˆ†æ {idx}/{total_jobs} ä¸ªèŒä½...")

    return tech_stats


def generate_analysis_report(tech_stats, total_jobs):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = {
        'æ€»èŒä½æ•°': total_jobs,
        'åˆ†ææ—¶é—´': None,
        'æŠ€æœ¯æ ˆç»Ÿè®¡': {},
        'é«˜é¢‘æŠ€æœ¯': {},
        'å­¦ä¹ å»ºè®®': []
    }

    # ç»Ÿè®¡æ¯ä¸ªæŠ€æœ¯ç±»åˆ«
    for category, counter in tech_stats.items():
        if counter:
            # è®¡ç®—å‡ºç°é¢‘ç‡
            freq = {tech: {'å‡ºç°æ¬¡æ•°': count, 'å æ¯”': f"{count/total_jobs*100:.1f}%"}
                   for tech, count in counter.most_common()}

            report['æŠ€æœ¯æ ˆç»Ÿè®¡'][category] = {
                'æŠ€æœ¯åˆ—è¡¨': freq,
                'æ€»è®¡': len(counter),
                'æœ€å¸¸ç”¨': counter.most_common(1)[0][0] if counter else None
            }

    # æå–é«˜é¢‘æŠ€æœ¯ï¼ˆå‡ºç°æ¬¡æ•° >= 3ï¼‰
    high_freq_techs = []
    for category, counter in tech_stats.items():
        for tech, count in counter.items():
            if count >= 3:
                high_freq_techs.append({
                    'æŠ€æœ¯': tech,
                    'ç±»åˆ«': category,
                    'å‡ºç°æ¬¡æ•°': count,
                    'å æ¯”': f"{count/total_jobs*100:.1f}%"
                })

    # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
    high_freq_techs.sort(key=lambda x: x['å‡ºç°æ¬¡æ•°'], reverse=True)
    report['é«˜é¢‘æŠ€æœ¯'] = high_freq_techs[:20]  # å–å‰20ä¸ª

    # ç”Ÿæˆå­¦ä¹ å»ºè®®
    report['å­¦ä¹ å»ºè®®'] = generate_learning_recommendations(report['é«˜é¢‘æŠ€æœ¯'])

    return report


def generate_learning_recommendations(high_freq_techs):
    """æ ¹æ®é«˜é¢‘æŠ€æœ¯ç”Ÿæˆå­¦ä¹ å»ºè®®"""
    recommendations = []

    if not high_freq_techs:
        return ["æš‚æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆå­¦ä¹ å»ºè®®"]

    # åˆ†ç±»ç»Ÿè®¡
    tech_by_category = {}
    for item in high_freq_techs:
        category = item['ç±»åˆ«']
        if category not in tech_by_category:
            tech_by_category[category] = []
        tech_by_category[category].append(item)

    # ç”Ÿæˆå»ºè®®
    for category, techs in tech_by_category.items():
        tech_names = [t['æŠ€æœ¯'] for t in techs[:5]]  # å–å‰5ä¸ª
        recommendations.append({
            'ç±»åˆ«': category,
            'æ ¸å¿ƒæŠ€æœ¯': tech_names,
            'é‡è¦æ€§': 'â­â­â­â­â­' if len(techs) >= 5 else 'â­â­â­â­',
            'å»ºè®®': f"é‡ç‚¹æŒæ¡ {', '.join(tech_names[:3])}"
        })

    return recommendations


def save_report(report, output_file):
    """ä¿å­˜åˆ†ææŠ¥å‘Š"""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


def print_summary(report):
    """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
    print("\n" + "="*70)
    print("æŠ€æœ¯æ ˆåˆ†ææŠ¥å‘Š")
    print("="*70)

    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡")
    print(f"  åˆ†æèŒä½æ•°: {report['æ€»èŒä½æ•°']}")

    print(f"\nğŸ”¥ é«˜é¢‘æŠ€æœ¯ (Top 10)")
    for idx, tech in enumerate(report['é«˜é¢‘æŠ€æœ¯'][:10], 1):
        print(f"  {idx}. {tech['æŠ€æœ¯']} ({tech['ç±»åˆ«']}) - å‡ºç° {tech['å‡ºç°æ¬¡æ•°']} æ¬¡ï¼Œå æ¯” {tech['å æ¯”']}")

    print(f"\nğŸ’¡ å­¦ä¹ å»ºè®®")
    for rec in report['å­¦ä¹ å»ºè®®'][:5]:
        print(f"  ã€{rec['ç±»åˆ«']}ã€‘{rec['é‡è¦æ€§']}")
        print(f"    æ ¸å¿ƒæŠ€æœ¯: {', '.join(rec['æ ¸å¿ƒæŠ€æœ¯'])}")
        print(f"    å»ºè®®: {rec['å»ºè®®']}")
        print()

    print("="*70)


# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("èŒä½æŠ€æœ¯æ ˆåˆ†æå·¥å…·")
    print("="*70)

    # 1. åŠ è½½èŒä½æè¿°
    descriptions = load_job_descriptions(INPUT_FILE)

    if not descriptions:
        print("\nâš  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„èŒä½æè¿°æ•°æ®")
        print("è¯·å…ˆè¿è¡Œçˆ¬è™«é‡‡é›†æ•°æ®: python boss_spider.py")
        return

    # 2. æå–æŠ€æœ¯æ ˆ
    tech_stats = extract_tech_stack(descriptions)

    # 3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = generate_analysis_report(tech_stats, len(descriptions))

    # 4. ä¿å­˜æŠ¥å‘Š
    save_report(report, OUTPUT_FILE)

    # 5. æ‰“å°æ‘˜è¦
    print_summary(report)

    print("\nâœ“ åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()
