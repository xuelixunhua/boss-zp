#!/usr/bin/python
# -*- coding:utf-8 -*-
"""
èŒä½æŠ€æœ¯æ ˆåˆ†ææ¨¡å—
ä» CSV æ–‡ä»¶è¯»å–èŒä½æè¿°ï¼Œåˆ†æå…±æ€§æŠ€æœ¯æ ˆï¼Œè¾“å‡ºå­¦ä¹ å»ºè®®
"""

import csv
import re
from collections import Counter
import json
import os

# ==================== é…ç½®å‚æ•° ====================

# è¾“å…¥æ–‡ä»¶ï¼ˆçˆ¬è™«ç”Ÿæˆçš„æ•°æ®ï¼‰
INPUT_FILE = 'data.csv'

# è¾“å‡ºæ–‡ä»¶
OUTPUT_FILE = 'tech_stack_analysis.json'

# å¤§æ¨¡å‹é…ç½®
USE_LLM = False  # æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹åˆ†æï¼ˆéœ€è¦ API Keyï¼‰
LLM_PROVIDER = 'qwen'  # å¯é€‰: 'qwen'(é€šä¹‰åƒé—®), 'openai', 'deepseek'

# API Key é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæ›´å®‰å…¨ï¼‰
# ä½¿ç”¨æ–¹æ³•ï¼šexport QWEN_API_KEY="your_api_key"
API_KEYS = {
    'qwen': os.getenv('QWEN_API_KEY', ''),
    'openai': os.getenv('OPENAI_API_KEY', ''),
    'deepseek': os.getenv('DEEPSEEK_API_KEY', '')
}

# æŠ€æœ¯æ ˆå…³é”®è¯åº“
TECH_KEYWORDS = {
    'ç¼–ç¨‹è¯­è¨€': [
        'Python', 'Java', 'JavaScript', 'TypeScript', 'Go', 'Golang',
        'C++', 'C#', 'Rust', 'PHP', 'Ruby', 'Swift', 'Kotlin', 'Scala'
    ],
    'å‰ç«¯æ¡†æ¶': [
        'React', 'Vue', 'Angular', 'Next.js', 'Nuxt.js',
        'uni-app', 'Flutter', 'Electron', 'React Native'
    ],
    'åç«¯æ¡†æ¶': [
        'Django', 'Flask', 'FastAPI', 'Spring Boot', 'Spring Cloud',
        'Express', 'Koa', 'Egg.js', 'Gin', 'Beego', 'Laravel'
    ],
    'AI/MLæ¡†æ¶': [
        'PyTorch', 'TensorFlow', 'Keras', 'scikit-learn', 'Pandas',
        'NumPy', 'Transformers', 'LangChain', 'OpenAI API', 'LLM',
        'Agent', 'RAG', 'Fine-tuning', 'Prompt Engineering'
    ],
    'æ•°æ®åº“': [
        'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Elasticsearch',
        'ClickHouse', 'Doris', 'Hive', 'HBase', 'OceanBase'
    ],
    'ä¸­é—´ä»¶/å·¥å…·': [
        'Kafka', 'RabbitMQ', 'RocketMQ', 'Docker', 'Kubernetes',
        'K8s', 'Jenkins', 'Git', 'GitLab', 'Linux', 'Nginx'
    ],
    'äº‘å¹³å°': [
        'AWS', 'Azure', 'GCP', 'é˜¿é‡Œäº‘', 'è…¾è®¯äº‘', 'åä¸ºäº‘',
        'Serverless', 'Lambda', 'Function Compute'
    ]
}

# ==================== å¤§æ¨¡å‹é›†æˆ ====================

def call_llm_analysis(descriptions, tech_stats):
    """ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æ"""
    if not USE_LLM:
        return None

    api_key = API_KEYS.get(LLM_PROVIDER)
    if not api_key:
        print(f"\nâš  æœªé…ç½® {LLM_PROVIDER} çš„ API Keyï¼Œè·³è¿‡å¤§æ¨¡å‹åˆ†æ")
        return None

    print(f"\nğŸ¤– ä½¿ç”¨ {LLM_PROVIDER} è¿›è¡Œæ·±åº¦åˆ†æ...")

    # å‡†å¤‡æç¤ºè¯
    prompt = build_analysis_prompt(descriptions, tech_stats)

    # è°ƒç”¨å¯¹åº”çš„å¤§æ¨¡å‹
    try:
        if LLM_PROVIDER == 'qwen':
            result = call_qwen_api(prompt, api_key)
        elif LLM_PROVIDER == 'openai':
            result = call_openai_api(prompt, api_key)
        elif LLM_PROVIDER == 'deepseek':
            result = call_deepseek_api(prompt, api_key)
        else:
            print(f"âš  ä¸æ”¯æŒçš„å¤§æ¨¡å‹: {LLM_PROVIDER}")
            return None

        print("âœ“ å¤§æ¨¡å‹åˆ†æå®Œæˆ")
        return result

    except Exception as e:
        print(f"âš  å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        return None


def build_analysis_prompt(descriptions, tech_stats):
    """æ„å»ºåˆ†ææç¤ºè¯"""
    # æå–é«˜é¢‘æŠ€æœ¯
    all_techs = []
    for category, counter in tech_stats.items():
        for tech, count in counter.most_common(10):
            all_techs.append(f"{tech}({count}æ¬¡)")

    tech_summary = ", ".join(all_techs[:30])

    # æå–éƒ¨åˆ†èŒä½æè¿°æ ·æœ¬
    sample_descs = [d['æè¿°'][:200] for d in descriptions[:5]]

    prompt = f"""è¯·åˆ†æä»¥ä¸‹ {len(descriptions)} ä¸ª AI Agent ç›¸å…³èŒä½çš„æŠ€æœ¯æ ˆéœ€æ±‚ï¼š

é«˜é¢‘æŠ€æœ¯ç»Ÿè®¡ï¼š
{tech_summary}

èŒä½æè¿°æ ·æœ¬ï¼š
{chr(10).join([f"{i+1}. {desc}..." for i, desc in enumerate(sample_descs)])}

è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š
1. æ ¸å¿ƒæŠ€æœ¯æ ˆï¼ˆå¿…é¡»æŒæ¡çš„æŠ€æœ¯ï¼ŒæŒ‰é‡è¦æ€§æ’åºï¼‰
2. æŠ€èƒ½ç­‰çº§è¦æ±‚ï¼ˆåˆçº§/ä¸­çº§/é«˜çº§åˆ†åˆ«éœ€è¦æŒæ¡ä»€ä¹ˆï¼‰
3. å­¦ä¹ è·¯çº¿å»ºè®®ï¼ˆä»é›¶å¼€å§‹çš„å­¦ä¹ é¡ºåºï¼‰
4. å·®å¼‚åŒ–ç«äº‰åŠ›ï¼ˆå“ªäº›æŠ€æœ¯èƒ½è®©ä½ è„±é¢–è€Œå‡ºï¼‰

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
  "æ ¸å¿ƒæŠ€æœ¯æ ˆ": ["æŠ€æœ¯1", "æŠ€æœ¯2", ...],
  "æŠ€èƒ½ç­‰çº§": {{"åˆçº§": [...], "ä¸­çº§": [...], "é«˜çº§": [...]}},
  "å­¦ä¹ è·¯çº¿": ["æ­¥éª¤1", "æ­¥éª¤2", ...],
  "å·®å¼‚åŒ–æŠ€æœ¯": ["æŠ€æœ¯1", "æŠ€æœ¯2", ...]
}}
"""
    return prompt


def call_qwen_api(prompt, api_key):
    """è°ƒç”¨é€šä¹‰åƒé—® API"""
    try:
        import dashscope
        from dashscope import Generation
    except ImportError:
        print("âš  è¯·å…ˆå®‰è£… dashscope: pip install dashscope")
        return None

    dashscope.api_key = api_key

    response = Generation.call(
        model='qwen-plus',  # æˆ– 'qwen-max' æ•ˆæœæ›´å¥½ä½†æ›´è´µ
        prompt=prompt,
        result_format='message'
    )

    if response.status_code == 200:
        content = response.output.choices[0].message.content
        # å°è¯•è§£æ JSON
        try:
            return json.loads(content)
        except:
            return {"åˆ†æç»“æœ": content}
    else:
        raise Exception(f"API è°ƒç”¨å¤±è´¥: {response.message}")


def call_openai_api(prompt, api_key):
    """è°ƒç”¨ OpenAI API"""
    try:
        from openai import OpenAI
    except ImportError:
        print("âš  è¯·å…ˆå®‰è£… openai: pip install openai")
        return None

    client = OpenAI(api_key=api_key)

    response = client.chat.completions.create(
        model="gpt-4",  # æˆ– 'gpt-3.5-turbo' æ›´ä¾¿å®œ
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ‹›è˜å’ŒèŒä¸šè§„åˆ’ä¸“å®¶ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    content = response.choices[0].message.content
    try:
        return json.loads(content)
    except:
        return {"åˆ†æç»“æœ": content}


def call_deepseek_api(prompt, api_key):
    """è°ƒç”¨ DeepSeek APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
    try:
        from openai import OpenAI
    except ImportError:
        print("âš  è¯·å…ˆå®‰è£… openai: pip install openai")
        return None

    client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )

    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ‹›è˜å’ŒèŒä¸šè§„åˆ’ä¸“å®¶ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    content = response.choices[0].message.content
    try:
        return json.loads(content)
    except:
        return {"åˆ†æç»“æœ": content}


# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================

def load_job_descriptions(csv_file):
    """ä»CSVæ–‡ä»¶åŠ è½½èŒä½æè¿°"""
    descriptions = []

    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            desc = row.get('èŒä½æè¿°', '').strip()
            if desc and len(desc) > 10:
                descriptions.append({
                    'èŒä½': row.get('èŒä½', ''),
                    'å…¬å¸': row.get('å…¬å¸', ''),
                    'è–ªèµ„': row.get('è–ªèµ„', ''),
                    'æè¿°': desc
                })

    print(f"âœ“ åŠ è½½äº† {len(descriptions)} ä¸ªèŒä½æè¿°")
    return descriptions


def extract_tech_stack(descriptions):
    """ä»èŒä½æè¿°ä¸­æå–æŠ€æœ¯æ ˆå…³é”®è¯"""
    print("\nå¼€å§‹åˆ†ææŠ€æœ¯æ ˆ...")

    tech_stats = {category: Counter() for category in TECH_KEYWORDS}
    total_jobs = len(descriptions)

    for idx, job in enumerate(descriptions, 1):
        desc = job['æè¿°']

        # éå†æ‰€æœ‰æŠ€æœ¯ç±»åˆ«
        for category, keywords in TECH_KEYWORDS.items():
            for keyword in keywords:
                # ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
                pattern = re.compile(re.escape(keyword), re.IGNORECASE)
                if pattern.search(desc):
                    tech_stats[category][keyword] += 1

        if idx % 10 == 0:
            print(f"  å·²åˆ†æ {idx}/{total_jobs} ä¸ªèŒä½...")

    return tech_stats


def generate_analysis_report(tech_stats, total_jobs):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = {
        'æ€»èŒä½æ•°': total_jobs,
        'åˆ†ææ—¶é—´': None,
        'æŠ€æœ¯æ ˆç»Ÿè®¡': {},
        'é«˜é¢‘æŠ€æœ¯': {},
        'å­¦ä¹ å»ºè®®': []
    }

    # ç»Ÿè®¡æ¯ä¸ªæŠ€æœ¯ç±»åˆ«
    for category, counter in tech_stats.items():
        if counter:
            # è®¡ç®—å‡ºç°é¢‘ç‡
            freq = {tech: {'å‡ºç°æ¬¡æ•°': count, 'å æ¯”': f"{count/total_jobs*100:.1f}%"}
                   for tech, count in counter.most_common()}

            report['æŠ€æœ¯æ ˆç»Ÿè®¡'][category] = {
                'æŠ€æœ¯åˆ—è¡¨': freq,
                'æ€»è®¡': len(counter),
                'æœ€å¸¸ç”¨': counter.most_common(1)[0][0] if counter else None
            }

    # æå–é«˜é¢‘æŠ€æœ¯ï¼ˆå‡ºç°æ¬¡æ•° >= 3ï¼‰
    high_freq_techs = []
    for category, counter in tech_stats.items():
        for tech, count in counter.items():
            if count >= 3:
                high_freq_techs.append({
                    'æŠ€æœ¯': tech,
                    'ç±»åˆ«': category,
                    'å‡ºç°æ¬¡æ•°': count,
                    'å æ¯”': f"{count/total_jobs*100:.1f}%"
                })

    # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
    high_freq_techs.sort(key=lambda x: x['å‡ºç°æ¬¡æ•°'], reverse=True)
    report['é«˜é¢‘æŠ€æœ¯'] = high_freq_techs[:20]  # å–å‰20ä¸ª

    # ç”Ÿæˆå­¦ä¹ å»ºè®®
    report['å­¦ä¹ å»ºè®®'] = generate_learning_recommendations(report['é«˜é¢‘æŠ€æœ¯'])

    return report


def generate_learning_recommendations(high_freq_techs):
    """æ ¹æ®é«˜é¢‘æŠ€æœ¯ç”Ÿæˆå­¦ä¹ å»ºè®®"""
    recommendations = []

    if not high_freq_techs:
        return ["æš‚æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆå­¦ä¹ å»ºè®®"]

    # åˆ†ç±»ç»Ÿè®¡
    tech_by_category = {}
    for item in high_freq_techs:
        category = item['ç±»åˆ«']
        if category not in tech_by_category:
            tech_by_category[category] = []
        tech_by_category[category].append(item)

    # ç”Ÿæˆå»ºè®®
    for category, techs in tech_by_category.items():
        tech_names = [t['æŠ€æœ¯'] for t in techs[:5]]  # å–å‰5ä¸ª
        recommendations.append({
            'ç±»åˆ«': category,
            'æ ¸å¿ƒæŠ€æœ¯': tech_names,
            'é‡è¦æ€§': 'â­â­â­â­â­' if len(techs) >= 5 else 'â­â­â­â­',
            'å»ºè®®': f"é‡ç‚¹æŒæ¡ {', '.join(tech_names[:3])}"
        })

    return recommendations


def save_report(report, output_file):
    """ä¿å­˜åˆ†ææŠ¥å‘Š"""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


def print_summary(report):
    """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
    print("\n" + "="*70)
    print("æŠ€æœ¯æ ˆåˆ†ææŠ¥å‘Š")
    print("="*70)

    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡")
    print(f"  åˆ†æèŒä½æ•°: {report['æ€»èŒä½æ•°']}")

    print(f"\nğŸ”¥ é«˜é¢‘æŠ€æœ¯ (Top 10)")
    for idx, tech in enumerate(report['é«˜é¢‘æŠ€æœ¯'][:10], 1):
        print(f"  {idx}. {tech['æŠ€æœ¯']} ({tech['ç±»åˆ«']}) - å‡ºç° {tech['å‡ºç°æ¬¡æ•°']} æ¬¡ï¼Œå æ¯” {tech['å æ¯”']}")

    print(f"\nğŸ’¡ å­¦ä¹ å»ºè®®")
    for rec in report['å­¦ä¹ å»ºè®®'][:5]:
        print(f"  ã€{rec['ç±»åˆ«']}ã€‘{rec['é‡è¦æ€§']}")
        print(f"    æ ¸å¿ƒæŠ€æœ¯: {', '.join(rec['æ ¸å¿ƒæŠ€æœ¯'])}")
        print(f"    å»ºè®®: {rec['å»ºè®®']}")
        print()

    print("="*70)


# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("èŒä½æŠ€æœ¯æ ˆåˆ†æå·¥å…·")
    print("="*70)

    # 1. åŠ è½½èŒä½æè¿°
    descriptions = load_job_descriptions(INPUT_FILE)

    if not descriptions:
        print("\nâš  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„èŒä½æè¿°æ•°æ®")
        print("è¯·å…ˆè¿è¡Œçˆ¬è™«é‡‡é›†æ•°æ®: python boss_spider.py")
        return

    # 2. æå–æŠ€æœ¯æ ˆ
    tech_stats = extract_tech_stack(descriptions)

    # 3. ä½¿ç”¨å¤§æ¨¡å‹æ·±åº¦åˆ†æï¼ˆå¯é€‰ï¼‰
    llm_analysis = call_llm_analysis(descriptions, tech_stats)

    # 4. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = generate_analysis_report(tech_stats, len(descriptions))

    # 5. åˆå¹¶å¤§æ¨¡å‹åˆ†æç»“æœ
    if llm_analysis:
        report['å¤§æ¨¡å‹åˆ†æ'] = llm_analysis

    # 6. ä¿å­˜æŠ¥å‘Š
    save_report(report, OUTPUT_FILE)

    # 7. æ‰“å°æ‘˜è¦
    print_summary(report)

    print("\nâœ“ åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()
